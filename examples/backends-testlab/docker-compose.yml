services:
  # ═══════════════════════════════════════════════════════════════════════════
  # Zerobyte
  # ═══════════════════════════════════════════════════════════════════════════
  zerobyte:
    image: ghcr.io/nicotsx/zerobyte:latest
    container_name: zerobyte
    restart: unless-stopped
    depends_on:
      minio-init:
        condition: service_completed_successfully
      sftp-keygen:
        condition: service_completed_successfully
      smb:
        condition: service_started
      webdav-vol:
        condition: service_started
      webdav-rclone:
        condition: service_started
      azurite:
        condition: service_started
      fakegcs:
        condition: service_started
      rest-server:
        condition: service_started
      sftp:
        condition: service_started
      nfs:
        condition: service_started
    cap_add:
      - SYS_ADMIN
    devices:
      - /dev/fuse:/dev/fuse
    ports:
      - "4096:4096"
    environment:
      - TZ=${TZ:-UTC}
      # ─── Volume credentials ───
      - SMB_USER=${SMB_USER}
      - SMB_PASSWORD=${SMB_PASSWORD}
      - WEBDAV_VOL_USER=${WEBDAV_VOL_USER}
      - WEBDAV_VOL_PASSWORD=${WEBDAV_VOL_PASSWORD}
      # ─── Repository credentials ───
      - S3_ACCESS_KEY_ID=${S3_ACCESS_KEY_ID}
      - S3_SECRET_ACCESS_KEY=${S3_SECRET_ACCESS_KEY}
      - R2_ACCESS_KEY_ID=${R2_ACCESS_KEY_ID}
      - R2_SECRET_ACCESS_KEY=${R2_SECRET_ACCESS_KEY}
      - AZURE_ACCOUNT_NAME=${AZURE_ACCOUNT_NAME}
      - AZURE_ACCOUNT_KEY=${AZURE_ACCOUNT_KEY}
      - GCS_PROJECT_ID=${GCS_PROJECT_ID}
      - GCS_CREDENTIALS_JSON=${GCS_CREDENTIALS_JSON}
      - REST_USER=${REST_USER}
      - REST_PASSWORD=${REST_PASSWORD}
      - SFTP_USER=${SFTP_USER}
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - zerobyte-data:/var/lib/zerobyte
      - ./testdata:/testdata:ro
      - sftp-keys:/run/secrets:ro
      - ./rclone.conf:/root/.config/rclone/rclone.conf:ro

  # ═══════════════════════════════════════════════════════════════════════════
  # TEST DATA GENERATOR
  # ═══════════════════════════════════════════════════════════════════════════
  # Generates random folders and files in all volume backends for testing
  testdata-init:
    image: alpine:latest
    container_name: testlab-testdata-init
    entrypoint: >
      /bin/sh -c "
      echo '=== Generating test data for all volume backends ===';

      generate_files() {
        local dir=$$1;
        local prefix=$$2;
        echo \"Generating files in $$dir ($$prefix)...\";

        mkdir -p \"$$dir/documents\" \"$$dir/images\" \"$$dir/logs\" \"$$dir/projects/app\" \"$$dir/projects/lib\";

        echo 'Hello from Zerobyte test lab!' > \"$$dir/README.txt\";
        date > \"$$dir/generated_at.txt\";

        for i in 1 2 3; do
          echo \"Document $$i content - $$prefix\" > \"$$dir/documents/doc_$$i.txt\";
          dd if=/dev/urandom bs=1024 count=$$((i * 10)) 2>/dev/null | base64 > \"$$dir/documents/data_$$i.bin\";
        done;

        for i in 1 2; do
          dd if=/dev/urandom bs=1024 count=50 2>/dev/null > \"$$dir/images/image_$$i.raw\";
        done;

        for i in 1 2 3 4 5; do
          echo \"[$$( date -Iseconds )] Log entry $$i from $$prefix\" >> \"$$dir/logs/app.log\";
        done;

        echo '{\"name\": \"test-app\", \"version\": \"1.0.0\"}' > \"$$dir/projects/app/package.json\";
        echo 'console.log(\"Hello World\");' > \"$$dir/projects/app/index.js\";
        echo 'export const VERSION = \"1.0.0\";' > \"$$dir/projects/lib/version.js\";

        echo \"Generated $$(find $$dir -type f | wc -l) files in $$dir\";
      };

      generate_files /data/local 'local-dir';
      generate_files /data/smb 'smb-share';
      generate_files /data/webdav-vol 'webdav-vol';
      generate_files /data/webdav-rclone 'webdav-rclone';
      generate_files /data/sftp 'sftp-upload';
      generate_files /data/nfs 'nfs-export';

      echo '=== Test data generation complete ===';
      "
    volumes:
      - ./testdata:/data/local
      - smb-data:/data/smb
      - webdav-vol-data:/data/webdav-vol
      - webdav-rclone-data:/data/webdav-rclone
      - sftp-data:/data/sftp
      - nfs-data:/data/nfs

  # ═══════════════════════════════════════════════════════════════════════════
  # VOLUME BACKENDS (sources to back up)
  # ═══════════════════════════════════════════════════════════════════════════

  # ─────────────────────────────────────────────────────────────────────────────
  # SMB server
  # ─────────────────────────────────────────────────────────────────────────────
  smb:
    image: dperson/samba
    container_name: testlab-smb
    restart: unless-stopped
    depends_on:
      testdata-init:
        condition: service_completed_successfully
    command: >
      -u "${SMB_USER};${SMB_PASSWORD}"
      -s "data;/data;no;no;no;${SMB_USER}"
    volumes:
      - smb-data:/data

  # ─────────────────────────────────────────────────────────────────────────────
  # WebDAV server (volume backend)
  # ─────────────────────────────────────────────────────────────────────────────
  webdav-vol:
    image: hacdias/webdav
    container_name: testlab-webdav-vol
    restart: unless-stopped
    depends_on:
      testdata-init:
        condition: service_completed_successfully
    environment:
      - USERNAME=${WEBDAV_VOL_USER}
      - PASSWORD=${WEBDAV_VOL_PASSWORD}
    command: ["--port", "6065"]
    volumes:
      - webdav-vol-data:/data

  # ─────────────────────────────────────────────────────────────────────────────
  # WebDAV server (for rclone backend)
  # ─────────────────────────────────────────────────────────────────────────────
  webdav-rclone:
    image: hacdias/webdav
    container_name: testlab-webdav-rclone
    restart: unless-stopped
    depends_on:
      testdata-init:
        condition: service_completed_successfully
    environment:
      - USERNAME=${RCLONE_WEBDAV_USER}
      - PASSWORD=${RCLONE_WEBDAV_PASSWORD}
    command: ["--port", "6065"]
    volumes:
      - webdav-rclone-data:/data

  # ─────────────────────────────────────────────────────────────────────────────
  # NFS server (requires privileged mode)
  # ─────────────────────────────────────────────────────────────────────────────
  nfs:
    image: erichough/nfs-server
    container_name: testlab-nfs
    restart: unless-stopped
    depends_on:
      testdata-init:
        condition: service_completed_successfully
    privileged: true
    environment:
      - NFS_EXPORT_0=/data *(rw,sync,no_subtree_check,no_root_squash)
    volumes:
      - nfs-data:/data

  # ═══════════════════════════════════════════════════════════════════════════
  # REPOSITORY BACKENDS (backup targets)
  # ═══════════════════════════════════════════════════════════════════════════

  # ─────────────────────────────────────────────────────────────────────────────
  # MinIO (S3 + R2 compatible)
  # ─────────────────────────────────────────────────────────────────────────────
  minio:
    image: minio/minio
    container_name: testlab-minio
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=${S3_ACCESS_KEY_ID}
      - MINIO_ROOT_PASSWORD=${S3_SECRET_ACCESS_KEY}
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO Console
    volumes:
      - minio-data:/data

  # Init container to create buckets and test data for S3, R2, and rclone
  minio-init:
    image: minio/mc
    container_name: testlab-minio-init
    depends_on:
      minio:
        condition: service_started
    entrypoint: >
      /bin/sh -c "
      sleep 3;
      mc alias set local http://minio:9000 ${S3_ACCESS_KEY_ID} ${S3_SECRET_ACCESS_KEY};
      
      echo '=== Creating buckets ===';
      mc mb --ignore-existing local/zerobyte;
      mc mb --ignore-existing local/zerobyte-r2;
      mc mb --ignore-existing local/zerobyte-rclone;
      mc mb --ignore-existing local/zerobyte-rclone-repo;
      
      echo '=== Generating test data in S3 buckets ===';
      
      echo 'Hello from Zerobyte S3 test data!' > /tmp/README.txt;
      date > /tmp/generated_at.txt;
      echo '{\"name\": \"s3-test-app\", \"version\": \"1.0.0\"}' > /tmp/package.json;
      echo 'console.log(\"Hello from S3\");' > /tmp/index.js;
      dd if=/dev/urandom bs=1024 count=20 2>/dev/null | base64 > /tmp/data_1.bin;
      dd if=/dev/urandom bs=1024 count=30 2>/dev/null | base64 > /tmp/data_2.bin;
      echo '[INFO] Log entry 1 from S3' > /tmp/app.log;
      echo '[INFO] Log entry 2 from S3' >> /tmp/app.log;
      
      for bucket in zerobyte-rclone; do
        echo \"Uploading test files to $$bucket...\";
        mc cp /tmp/README.txt local/$$bucket/README.txt;
        mc cp /tmp/generated_at.txt local/$$bucket/generated_at.txt;
        mc cp /tmp/package.json local/$$bucket/projects/app/package.json;
        mc cp /tmp/index.js local/$$bucket/projects/app/index.js;
        mc cp /tmp/data_1.bin local/$$bucket/documents/data_1.bin;
        mc cp /tmp/data_2.bin local/$$bucket/documents/data_2.bin;
        mc cp /tmp/app.log local/$$bucket/logs/app.log;
      done;
      
      echo '=== MinIO initialization complete ===';
      exit 0;
      "

  # ─────────────────────────────────────────────────────────────────────────────
  # Azurite (Azure Blob Storage emulator)
  # ─────────────────────────────────────────────────────────────────────────────
  azurite:
    image: mcr.microsoft.com/azure-storage/azurite
    container_name: testlab-azurite
    restart: unless-stopped
    command: azurite-blob --blobHost 0.0.0.0
    ports:
      - "10000:10000"
    volumes:
      - azurite-data:/data

  # ─────────────────────────────────────────────────────────────────────────────
  # fake-gcs-server (Google Cloud Storage emulator)
  # ─────────────────────────────────────────────────────────────────────────────
  fakegcs:
    image: fsouza/fake-gcs-server
    container_name: testlab-fakegcs
    restart: unless-stopped
    command: -scheme http -port 4443 -external-url http://fakegcs:4443
    ports:
      - "4443:4443"
    volumes:
      - fakegcs-data:/data

  # ─────────────────────────────────────────────────────────────────────────────
  # Restic REST Server
  # ─────────────────────────────────────────────────────────────────────────────
  rest-server:
    image: restic/rest-server
    container_name: testlab-rest-server
    restart: unless-stopped
    environment:
      - OPTIONS=--no-auth
    ports:
      - "8000:8000"
    volumes:
      - rest-server-data:/data

  # ─────────────────────────────────────────────────────────────────────────────
  # SFTP server
  # ─────────────────────────────────────────────────────────────────────────────
  # Generate SSH key pair for SFTP authentication
  sftp-keygen:
    image: alpine:latest
    container_name: testlab-sftp-keygen
    entrypoint: >
      /bin/sh -c "
      if [ ! -f /keys/sftp_key ]; then
        apk add --no-cache openssh-keygen;
        ssh-keygen -t ed25519 -f /keys/sftp_key -N '' -C 'zerobyte-testlab';
        chmod 600 /keys/sftp_key;
        chmod 644 /keys/sftp_key.pub;
        echo 'SSH key pair generated successfully';
      else
        echo 'SSH key pair already exists, skipping generation';
      fi
      "
    volumes:
      - sftp-keys:/keys

  sftp:
    image: atmoz/sftp
    container_name: testlab-sftp
    restart: unless-stopped
    depends_on:
      sftp-keygen:
        condition: service_completed_successfully
      testdata-init:
        condition: service_completed_successfully
    command: "${SFTP_USER}::1000:1000:upload"
    ports:
      - "2222:22"
    volumes:
      - sftp-data:/home/${SFTP_USER}/upload
      - sftp-keys:/home/${SFTP_USER}/.ssh/keys:ro

volumes:
  zerobyte-data:
  smb-data:
  webdav-vol-data:
  webdav-rclone-data:
  nfs-data:
  minio-data:
  azurite-data:
  fakegcs-data:
  rest-server-data:
  sftp-data:
  sftp-keys:
